{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T16:39:37.819205Z",
     "start_time": "2025-06-20T16:39:37.541318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "from random import random\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from vpc3_proyecto.data.utils import  get_data, load_annotations, get_annotated_image_ids, image_id_to_train_filename, \\\n",
    "    extract_annotated_images, split_subset\n",
    "\n",
    "\n",
    "\n",
    "# 1. Load environment variables\n",
    "# Cargar las variables de entorno\n",
    "print('loading env from ',)\n",
    "load_dotenv(os.path.join(\"..\",\".env\"))\n",
    "\n",
    "PROCESSED_DATA_DIR = os.getenv(\"PROCESSED_DATA_DIR\")\n",
    "RAW_DATA_DIR = os.getenv(\"RAW_DATA_DIR\")\n",
    "\n",
    "if not all([RAW_DATA_DIR, PROCESSED_DATA_DIR]):\n",
    "    print(\"‚ùå Failed to load environment variables. Exiting.\")\n",
    "    \n",
    "ANN_COCO_TEXT_DIR = os.path.join(PROCESSED_DATA_DIR,\"cocotext.v2.json\")\n",
    "\n",
    "# Get split percentages\n",
    "TRAIN_SPLIT_PERCENTAGE = float(os.getenv(\"TRAIN_SPLIT_PERCENTAGE\", \"0.7\"))\n",
    "VALID_SPLIT_PERCENTAGE = float(os.getenv(\"VALID_SPLIT_PERCENTAGE\", \"0.2\"))\n",
    "TEST_SPLIT_PERCENTAGE = float(os.getenv(\"TEST_SPLIT_PERCENTAGE\", \"0.1\"))\n",
    "\n",
    "\n",
    "print(\"\\n=== Starting Data Processing Workflow ===\")\n",
    "print(f\"Split percentages - Train: {TRAIN_SPLIT_PERCENTAGE*100}%, \"\n",
    "      f\"Validation: {VALID_SPLIT_PERCENTAGE*100}%, \"\n",
    "      f\"Test: {TEST_SPLIT_PERCENTAGE*100}%\")\n"
   ],
   "id": "65c7b839e400735",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading env from \n",
      "\n",
      "=== Starting Data Processing Workflow ===\n",
      "Split percentages - Train: 70.0%, Validation: 20.0%, Test: 10.0%\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T16:39:42.577234Z",
     "start_time": "2025-06-20T16:39:42.573446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 3. Download datasets\n",
    "print(\"\\nüîΩ Downloading datasets...\")\n",
    "get_data(RAW_DATA_DIR)\n",
    "\n",
    "# 4. Prepare paths\n",
    "annotations_zip = os.path.join(RAW_DATA_DIR, \"cocotext.v2.zip\")\n",
    "train_zip = os.path.join(RAW_DATA_DIR, \"train2014.zip\")\n",
    "\n",
    "# Verify downloads\n",
    "if not os.path.exists(annotations_zip):\n",
    "    print(f\"‚ùå Error: Annotations file not found at {annotations_zip}\")\n",
    "    \n",
    "if not os.path.exists(train_zip):\n",
    "    print(f\"‚ùå Error: Train images not found at {train_zip}\")\n",
    "    "
   ],
   "id": "b415801af04cd7eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîΩ Downloading datasets...\n",
      "cocotext.v2.zip ya existe. Omitiendo descarga.\n",
      "train2014.zip ya existe. Omitiendo descarga.\n",
      "Descarga finalizada.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T16:39:58.179197Z",
     "start_time": "2025-06-20T16:39:57.353151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "# 5. Load annotations and get annotated image IDs\n",
    "print(\"\\nüìñ Loading annotations...\")\n",
    "coco_data = load_annotations(annotations_zip)\n",
    "annotated_ids = get_annotated_image_ids(coco_data)\n",
    "total_images = len(annotated_ids)\n",
    "print(f\"‚úÖ Found {len(annotated_ids)} annotated images\")\n",
    "## achicamos dataset para poder entrenar con menos recursos.. (10k imagenes iniciales, que luego se multiplicaran por multiples detecciones)\n",
    "# if len(annotated_ids) > 5000:\n",
    "#     annotated_ids = set(random.sample(list(annotated_ids), 5000)) if len(annotated_ids) > 5000 else annotated_ids\n"
   ],
   "id": "ff9e98a221168b9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìñ Loading annotations...\n",
      "‚úÖ Found 23485 annotated images\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T00:49:29.641774Z",
     "start_time": "2025-06-20T00:49:29.640374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "len(annotated_ids)\n",
    "total_images = len(annotated_ids)\n"
   ],
   "id": "c2a15ce031c03932",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T16:40:30.153227Z",
     "start_time": "2025-06-20T16:40:16.810217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 6. Calculate split sizes\n",
    "val_count = int(total_images * VALID_SPLIT_PERCENTAGE)\n",
    "test_count = int(total_images * TEST_SPLIT_PERCENTAGE)\n",
    "\n",
    "# Train count will be whatever remains after validation/test\n",
    "# 6. OBTENEMOS FILENAMES DE IMAGENES QUE TIENEN ANOTACIONES\n",
    "train_filenames = {image_id_to_train_filename(img_id) for img_id in annotated_ids}\n",
    "\n",
    "# 7. EXTRAEMOS TODAS LAS IMAGENES QUE TIENEN ANOTACIONES, LUEGO MOVEMOS  SUBSETS DE ESTE A VALIDACION / TEST\n",
    "print(\"\\nüì¶ Extracting annotated images...\")\n",
    "try:\n",
    "    extract_dir = os.path.join(RAW_DATA_DIR,\"train2014\")\n",
    "    extract_annotated_images(train_zip, extract_dir, train_filenames)\n",
    "    print(f\"‚úÖ Extracted {len(train_filenames)} images to {extract_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error extracting images: {str(e)}\")\n",
    "    "
   ],
   "id": "f6627e3d51a90176",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Extracting annotated images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting from train2014.zip: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23485/23485 [00:12<00:00, 1853.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracted 23485 images to /home/juan/CEIA/CEIA-ViT/TrabajosPracticos/TP_Final/data/raw/train2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T16:40:33.139912Z",
     "start_time": "2025-06-20T16:40:33.013992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "print(f\"\\nüîÑ Creating validation set '({val_count} images)'...\")\n",
    "val_dir = os.path.join(RAW_DATA_DIR, \"val2014\")\n",
    "try:\n",
    "    split_subset(\n",
    "        source_dir=extract_dir,\n",
    "        target_dir=val_dir,\n",
    "        val_count=val_count,\n",
    "        move=True\n",
    "    )\n",
    "    val_count = len(os.listdir(val_dir))\n",
    "    print(f\"‚úÖ Created validation set with {val_count} images at {val_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating validation set: {str(e)}\")\n",
    "   "
   ],
   "id": "155c3f87348b76ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Creating validation set '(4697 images)'...\n",
      "4697 im√°genes movidas a '/home/juan/CEIA/CEIA-ViT/TrabajosPracticos/TP_Final/data/raw/val2014'.\n",
      "‚úÖ Created validation set with 4697 images at /home/juan/CEIA/CEIA-ViT/TrabajosPracticos/TP_Final/data/raw/val2014\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T16:40:38.390041Z",
     "start_time": "2025-06-20T16:40:38.320633Z"
    }
   },
   "cell_type": "code",
   "source": [
    " \n",
    "\n",
    "print(f\"\\nüîÑ Creating test set ({test_count} images)...\")\n",
    "test_dir = os.path.join(RAW_DATA_DIR, \"test2014\")\n",
    "try:\n",
    "    split_subset(\n",
    "        source_dir=extract_dir,\n",
    "        target_dir=test_dir,\n",
    "        val_count=test_count,\n",
    "        move=True\n",
    "    )\n",
    "    test_count = len(os.listdir(test_dir))\n",
    "    print(f\"‚úÖ Created test set with {test_count} images at {test_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating test set: {str(e)}\")\n",
    "    \n"
   ],
   "id": "f6d7235bcf34493b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Creating test set (2348 images)...\n",
      "2348 im√°genes movidas a '/home/juan/CEIA/CEIA-ViT/TrabajosPracticos/TP_Final/data/raw/test2014'.\n",
      "‚úÖ Created test set with 2348 images at /home/juan/CEIA/CEIA-ViT/TrabajosPracticos/TP_Final/data/raw/test2014\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
