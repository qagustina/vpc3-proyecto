{
 "cells": [
  {
   "cell_type": "code",
   "id": "e3d2a2a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:38:50.235568Z",
     "start_time": "2025-06-15T23:38:50.195750Z"
    }
   },
   "source": [
    "import zipfile\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import random\n",
    "import requests"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "0d07ef22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T20:12:46.301132Z",
     "start_time": "2025-06-14T20:12:46.297771Z"
    }
   },
   "source": [
    "data_folder = \"/home/juan/CEIA/CEIA-ViT/TrabajosPracticos/TP_Final/data/raw/\"\n",
    "\n",
    "def get_data():\n",
    "    os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "    urls = {\n",
    "        \"cocotext.v2.zip\": \"https://bgshih.github.io/cocotext/cocotext.v2.zip\",\n",
    "        \"train2014.zip\": \"http://images.cocodataset.org/zips/train2014.zip\"\n",
    "    }\n",
    "\n",
    "    for name_file, url in urls.items():\n",
    "        ruta_destino = os.path.join(data_folder, name_file)\n",
    "        if os.path.exists(ruta_destino):\n",
    "            print(f\"{name_file} ya existe. Omitiendo descarga.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Descargando {name_file}...\")\n",
    "        respuesta = requests.get(url, stream=True)\n",
    "        total = int(respuesta.headers.get('content-length', 0))\n",
    "\n",
    "        with open(ruta_destino, 'wb') as archivo, tqdm(\n",
    "            desc=name_file,\n",
    "            total=total,\n",
    "            unit='B',\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024\n",
    "        ) as barra:\n",
    "            for datos in respuesta.iter_content(chunk_size=1024):\n",
    "                archivo.write(datos)\n",
    "                barra.update(len(datos))\n",
    "\n",
    "    print(\"Descarga finalizada.\")\n",
    "\n",
    "get_data()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cocotext.v2.zip ya existe. Omitiendo descarga.\n",
      "train2014.zip ya existe. Omitiendo descarga.\n",
      "Descarga finalizada.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "0ed2b0d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T20:12:50.691431Z",
     "start_time": "2025-06-14T20:12:50.688890Z"
    }
   },
   "source": [
    "def count_images(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "        return len([f for f in zipf.namelist() if f.lower().endswith('.jpg')])\n",
    "\n",
    "def extract_anns(zip_path, json_filename='cocotext.v2.json'):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "        with zipf.open(json_filename) as json_file:\n",
    "            return json.load(json_file)\n",
    "        \n",
    "def contar_labeled(coco_text_data):\n",
    "    etiquetadas = set()\n",
    "    for ann_id, ann in coco_text_data['anns'].items():\n",
    "        img_id = ann['image_id']\n",
    "        if ann['legibility'] in ['legible', 'illegible']:\n",
    "            etiquetadas.add(img_id)\n",
    "    return len(etiquetadas)\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "08cb9d59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T20:14:50.031013Z",
     "start_time": "2025-06-14T20:14:48.888740Z"
    }
   },
   "source": [
    "train_zip = data_folder + 'train2014.zip'\n",
    "annotations_zip = data_folder+'cocotext.v2.zip'\n",
    "\n",
    "num_train_imgs = count_images(train_zip)\n",
    "\n",
    "coco_text = extract_anns(annotations_zip)\n",
    "\n",
    "num_etiquetadas = contar_labeled(coco_text)\n",
    "\n",
    "print(f'Imágenes en train2014.zip: {num_train_imgs}')\n",
    "print(f'Imágenes etiquetadas (con texto): {num_etiquetadas}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes en train2014.zip: 82783\n",
      "Imágenes etiquetadas (con texto): 23485\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "598fb85e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T20:15:37.701852Z",
     "start_time": "2025-06-14T20:15:37.698380Z"
    }
   },
   "source": [
    "def image_id_to_train_filename(image_id):\n",
    "    return f'COCO_train2014_{image_id:012d}.jpg'\n",
    "\n",
    "\n",
    "def load_annotations(zip_path, json_filename='cocotext.v2.json'):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "        with zipf.open(json_filename) as file:\n",
    "            return json.load(file)\n",
    "\n",
    "\n",
    "def get_annotated_image_ids(coco_data):\n",
    "    annotated_ids = set()\n",
    "    for ann in coco_data['anns'].values():\n",
    "        annotated_ids.add(ann['image_id'])\n",
    "    return annotated_ids\n",
    "\n",
    "\n",
    "def extract_annotated_images(zip_path, output_dir, target_filenames):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "        zip_files = zipf.namelist()\n",
    "        # Match full paths like 'train2014/COCO_train2014_000000001234.jpg'\n",
    "        matched_files = [f for f in zip_files if os.path.basename(f) in target_filenames]\n",
    "\n",
    "        if not matched_files:\n",
    "            print(f'No matching files found in {zip_path}')\n",
    "            return\n",
    "\n",
    "        for file in tqdm(matched_files, desc=f'Extracting from {os.path.basename(zip_path)}'):\n",
    "            zipf.extract(file, output_dir)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "1dd92f6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T20:15:53.907116Z",
     "start_time": "2025-06-14T20:15:40.224985Z"
    }
   },
   "source": [
    "output_dir = '../data/raw/subset/train2014'\n",
    "\n",
    "# load annotations and get annotated image IDs\n",
    "coco_data = load_annotations(annotations_zip)\n",
    "annotated_ids = get_annotated_image_ids(coco_data)\n",
    "\n",
    "# convert IDs to expected filenames\n",
    "train_filenames = set(image_id_to_train_filename(img_id) for img_id in annotated_ids)\n",
    "\n",
    "# extract only annotated images from train2014.zip\n",
    "extract_annotated_images(train_zip, output_dir, train_filenames)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting from train2014.zip: 100%|██████████| 23485/23485 [00:11<00:00, 1958.58it/s]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "5c6080c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T20:17:22.808528Z",
     "start_time": "2025-06-14T20:17:22.804751Z"
    }
   },
   "source": [
    "23485 / 3"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7828.333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "d853dc4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:38:55.568383Z",
     "start_time": "2025-06-15T23:38:55.565602Z"
    }
   },
   "source": [
    "def split_validation_set(source_dir, target_dir, val_count=7829, seed=42, move=False):\n",
    "\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    \n",
    "    all_images = [f for f in os.listdir(source_dir) if f.lower().endswith('.jpg')]\n",
    "    \n",
    "    if val_count > len(all_images):\n",
    "        raise ValueError(f\"Se solicitaron {val_count} imágenes, pero solo hay {len(all_images)} disponibles.\")\n",
    "    \n",
    "    random.seed(seed)\n",
    "    selected_images = random.sample(all_images, val_count)\n",
    "    \n",
    "    for filename in selected_images:\n",
    "        src_path = os.path.join(source_dir, filename)\n",
    "        dst_path = os.path.join(target_dir, filename)\n",
    "        if move:\n",
    "            shutil.move(src_path, dst_path)\n",
    "        else:\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "\n",
    "    print(f\"{val_count} imágenes {'movidas' if move else 'copiadas'} a '{target_dir}'.\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "fbd66e5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T20:19:29.645360Z",
     "start_time": "2025-06-14T20:19:29.454134Z"
    }
   },
   "source": [
    "split_validation_set(\n",
    "    source_dir='../data/raw/subset/train2014/train2014',\n",
    "    target_dir='../data/raw/subset/val2014',\n",
    "    val_count=7829,\n",
    "    move=True  \n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7829 imágenes movidas a '../data/raw/subset/val2014'.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:39:00.754117Z",
     "start_time": "2025-06-15T23:39:00.717376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "split_validation_set(\n",
    "    source_dir='../data/raw/subset/val2014',\n",
    "    target_dir='../data/raw/subset/test2014',\n",
    "    val_count=700,\n",
    "    move=True  \n",
    ")"
   ],
   "id": "ab5f391600fdefb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 imágenes movidas a '../data/raw/subset/test2014'.\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
