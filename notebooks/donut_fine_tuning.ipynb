{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3wJhpcpoCOa"
   },
   "source": [
    "# Donut Fine-tuning\n",
    "\n",
    "El presente notebook es el proceso de fine-tuning para [DoNut-base](https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://huggingface.co/naver-clova-ix/donut-base-finetuned-cord-v2&ved=2ahUKEwjMh4O54vGNAxVsIrkGHQznKskQFnoECBcQAQ&usg=AOvVaw1uKtlO2jgCL6oC_haM4FIB)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqdq_7b14tMU",
    "outputId": "9d7e3bc5-96a4-47ed-908b-44e0c1cd5fe8",
    "ExecuteTime": {
     "end_time": "2025-06-19T14:35:06.866078Z",
     "start_time": "2025-06-19T14:35:05.512404Z"
    }
   },
   "source": [
    "pip install datasets transformers"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (3.6.0)\r\n",
      "Requirement already satisfied: transformers in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (4.52.4)\r\n",
      "Requirement already satisfied: filelock in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from datasets) (3.13.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from datasets) (1.26.4)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from datasets) (18.1.0)\r\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\r\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: pandas in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from datasets) (2.2.2)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from datasets) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from datasets) (4.66.5)\r\n",
      "Requirement already satisfied: xxhash in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from datasets) (0.70.15)\r\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from datasets) (0.31.4)\r\n",
      "Requirement already satisfied: packaging in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from datasets) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from datasets) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from transformers) (0.21.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\r\n",
      "Installing collected packages: dill\r\n",
      "  Attempting uninstall: dill\r\n",
      "    Found existing installation: dill 0.4.0\r\n",
      "    Uninstalling dill-0.4.0:\r\n",
      "      Successfully uninstalled dill-0.4.0\r\n",
      "Successfully installed dill-0.3.8\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aA-6FGao5Jih",
    "ExecuteTime": {
     "end_time": "2025-06-19T14:35:11.254951Z",
     "start_time": "2025-06-19T14:35:07.979055Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "#from transformers import MobileViTForImageClassification, MobileViTImageProcessor\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_ItemsView' from 'multidict._multidict' (/home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages/multidict/_multidict.cpython-312-x86_64-linux-gnu.so)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dataset\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#from transformers import MobileViTForImageClassification, MobileViTImageProcessor\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ViTForImageClassification, ViTImageProcessor, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/datasets/__init__.py:37\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m pyarrow\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m version\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01marrow_dataset\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dataset, concatenate_datasets\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01marrow_reader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ReadInstruction\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbuilder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ArrowBasedBuilder, BeamBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/datasets/arrow_dataset.py:61\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01marrow_reader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ArrowReader\n\u001B[0;32m---> 61\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01marrow_writer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ArrowWriter, OptimizedTypedSequence\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeatures\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Audio, ClassLabel, Features, Image, Sequence, Value\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeatures\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeatures\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FeatureType, _ArrayXD, decode_nested_example, pandas_types_mapper, require_decoding\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/datasets/arrow_writer.py:26\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyarrow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpa\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[0;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeatures\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Features, Image, Value\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeatures\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeatures\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     28\u001B[0m     FeatureType,\n\u001B[1;32m     29\u001B[0m     _ArrayXDExtensionType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     34\u001B[0m     numpy_to_pyarrow_listarray,\n\u001B[1;32m     35\u001B[0m )\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minfo\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DatasetInfo\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/datasets/features/__init__.py:17\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# flake8: noqa\u001B[39;00m\n\u001B[1;32m      3\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAudio\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArray2D\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTranslationVariableLanguages\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     16\u001B[0m ]\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Audio\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeatures\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Array2D, Array3D, Array4D, Array5D, ClassLabel, Features, Sequence, Value\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/datasets/features/audio.py:12\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtable\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m array_cast\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpy_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m no_op_if_value_is_null, string_to_dict\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstreaming_download_manager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m xopen\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeatures\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FeatureType\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/datasets/utils/streaming_download_manager.py:16\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxml\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01metree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ElementTree \u001B[38;5;28;01mas\u001B[39;00m ET\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mfsspec\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01maiohttp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclient_exceptions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ClientError\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfilesystems\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m COMPRESSION_FILESYSTEMS\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/aiohttp/__init__.py:5\u001B[0m\n\u001B[1;32m      1\u001B[0m __version__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m3.12.13\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TYPE_CHECKING, Tuple\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m hdrs \u001B[38;5;28;01mas\u001B[39;00m hdrs\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclient\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      7\u001B[0m     BaseConnector,\n\u001B[1;32m      8\u001B[0m     ClientConnectionError,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     48\u001B[0m     request,\n\u001B[1;32m     49\u001B[0m )\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclient_middleware_digest_auth\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DigestAuthMiddleware\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/aiohttp/hdrs.py:8\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Final, Set\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmultidict\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m istr\n\u001B[1;32m     10\u001B[0m METH_ANY: Final[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     11\u001B[0m METH_CONNECT: Final[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCONNECT\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/multidict/__init__.py:40\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mabc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ItemsView, KeysView, ValuesView\n\u001B[0;32m---> 40\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_multidict\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     41\u001B[0m         CIMultiDict,\n\u001B[1;32m     42\u001B[0m         CIMultiDictProxy,\n\u001B[1;32m     43\u001B[0m         MultiDict,\n\u001B[1;32m     44\u001B[0m         MultiDictProxy,\n\u001B[1;32m     45\u001B[0m         _ItemsView,\n\u001B[1;32m     46\u001B[0m         _KeysView,\n\u001B[1;32m     47\u001B[0m         _ValuesView,\n\u001B[1;32m     48\u001B[0m         getversion,\n\u001B[1;32m     49\u001B[0m         istr,\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     MultiMapping\u001B[38;5;241m.\u001B[39mregister(MultiDictProxy)\n\u001B[1;32m     53\u001B[0m     MutableMultiMapping\u001B[38;5;241m.\u001B[39mregister(MultiDict)\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name '_ItemsView' from 'multidict._multidict' (/home/juan/anaconda3/envs/CEIA/lib/python3.12/site-packages/multidict/_multidict.cpython-312-x86_64-linux-gnu.so)"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T20:34:10.026825Z",
     "start_time": "2025-06-18T20:34:09.908252Z"
    }
   },
   "source": [
    "device =  'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(device) # Expected: ‘cuda’ if Linux else ‘mps’ if MacOS\n",
    "device =  'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T20:31:24.444920Z",
     "start_time": "2025-06-18T20:31:24.443354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import transformers\n",
    "\n",
    "print(torch.__version__)\n",
    "print(transformers.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126\n",
      "4.52.4\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcyWg-Ii5AC6"
   },
   "source": [
    "# Descargando modelos"
   ]
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fL7GJ_kQX0_g",
    "outputId": "a58c0f17-a7f2-44ac-8da8-05b59a97f26b",
    "ExecuteTime": {
     "end_time": "2025-06-18T21:00:02.137013Z",
     "start_time": "2025-06-18T21:00:02.075243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Try different .env paths\n",
    "env_path = os.path.join(\"..\",\"vpc3_proyecto\",\".env\")\n",
    "# env path using os path join\n",
    "    \n",
    "print(f\"🔍 Trying .env path: {env_path}\")\n",
    "\n",
    "# Load environment variables\n",
    "found = load_dotenv(env_path)\n",
    "print(f\"✅ .env file {'found' if found else 'not found'}\")\n",
    "\n",
    "# Verify loaded variables\n",
    "print(\"\\n🔎 Environment variables:\")\n",
    "for var in [\"PROCESSED_DATA_DIR\", \"RAW_DATA_DIR\", \"CHECKPOINT_DIR\"]:\n",
    "    value = os.getenv(var)\n",
    "    print(f\"{var}: {'✅' if value else '❌'} {value}\")\n",
    "\n",
    "img_dir_train = os.path.join(os.getenv(\"PROCESSED_DATA_DIR\"),'train2014')\n",
    "img_dir_val = os.path.join(os.getenv(\"PROCESSED_DATA_DIR\"),'val2014')\n",
    "img_dir_test =  os.path.join(os.getenv(\"PROCESSED_DATA_DIR\"),'test2014')\n",
    "ann_coco_text = os.path.join(os.getenv(\"RAW_DATA_DIR\"),'cocotext.v2.zip')\n",
    "\n",
    "print(ann_coco_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Trying .env path: ../vpc3_proyecto/.env\n",
      "✅ .env file found\n",
      "\n",
      "🔎 Environment variables:\n",
      "PROCESSED_DATA_DIR: ✅ /home/juan/CEIA/vpc3-proyecto/vpc3_proyecto/data/processed\n",
      "RAW_DATA_DIR: ✅ /home/juan/CEIA/CEIA-ViT/TrabajosPracticos/TP_Final/data/raw\n",
      "CHECKPOINT_DIR: ✅ /home/juan/CEIA/vpc3-proyecto/vpc3_proyecto/models\n",
      "/home/juan/CEIA/CEIA-ViT/TrabajosPracticos/TP_Final/data/raw/cocotext.v2.zip\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dIi12TzP5Czj",
    "ExecuteTime": {
     "end_time": "2025-06-19T14:35:31.879543Z",
     "start_time": "2025-06-19T14:35:23.557214Z"
    }
   },
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base-finetuned-cord-v2\")\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base-finetuned-cord-v2\")\n",
    "\n",
    "# 1. First fix the model configuration\n",
    "model.config.decoder_start_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.decoder_start_token_id = processor.tokenizer.convert_tokens_to_ids(\"<s_cord-v2>\")  # MUST match prompt!"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 11:35:25.667902: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-19 11:35:25.800361: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750343725.849711  111933 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750343725.864003  111933 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750343725.973993  111933 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750343725.974013  111933 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750343725.974015  111933 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750343725.974016  111933 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-19 11:35:25.987405: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T21:00:39.849910Z",
     "start_time": "2025-06-18T21:00:36.347405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from vpc3_proyecto.model_training.dataset_donut_model import DonutTextDatasetFromCocoTextV2Raw\n",
    "\n",
    "train_dataset = DonutTextDatasetFromCocoTextV2Raw(img_dir_train, ann_coco_text, processor=processor)\n",
    "val_dataset = DonutTextDatasetFromCocoTextV2Raw(img_dir_val, ann_coco_text, processor=processor)\n",
    "test_dataset = DonutTextDatasetFromCocoTextV2Raw(img_dir_test, ann_coco_text, processor=processor)\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T21:00:43.371823Z",
     "start_time": "2025-06-18T21:00:43.364460Z"
    }
   },
   "cell_type": "code",
   "source": "val_dataset.__len__()\n",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4697"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T21:00:45.260826Z",
     "start_time": "2025-06-18T21:00:45.258793Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset.__len__()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16440"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T21:00:46.696517Z",
     "start_time": "2025-06-18T21:00:46.691102Z"
    }
   },
   "cell_type": "code",
   "source": "test_dataset.__len__()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2348"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Inferencia con modelo preentrenado (sin finetuning)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Ejemplo: Imagen y texto originales "
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T21:01:01.146474Z",
     "start_time": "2025-06-18T21:01:01.068681Z"
    }
   },
   "cell_type": "code",
   "source": "sample = train_dataset[0]",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T21:01:02.593442Z",
     "start_time": "2025-06-18T21:01:02.530661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "first_text = processor.tokenizer.decode(sample[\"labels\"][sample[\"labels\"] != -100])  # Decode the text labels\n",
    "\n",
    "# If you want to see the actual PIL image before processing:\n",
    "original_image = Image.open(sample[\"img_path\"]).convert(\"RGB\")\n",
    "\n",
    "# Display results\n",
    "print(\"Ground truth Text:\", first_text)\n",
    "original_image.show()  # This will display the original image"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth Text: <s> 35 LIMIT SPEED</s>\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Probamos inferir con el modelo tal cual viene (misma imagen)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T14:36:51.697321Z",
     "start_time": "2025-06-19T14:36:51.695117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "image_path = \"../imgs/date.png\"\n",
    "try:\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Image not found at {image_path}\")\n",
    "    exit()\n",
    "\n",
    "from vpc3_proyecto.visualization.infer_from_image import infer_text_from_image\n",
    "task_prompt = \"<s>\""
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T14:37:42.046862Z",
     "start_time": "2025-06-19T14:37:41.703015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from vpc3_proyecto.visualization.infer_from_image import infer_text_from_image\n",
    "task_prompt = \"<s_cord-v2>\"\n",
    "\n",
    "result_text = infer_text_from_image(image, model, processor,task_prompt=task_prompt)\n",
    "print(\"Texto detectado:\", result_text)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto detectado: <s_menu><s_nm> Yiernes 28 de noviembre de 1986</s_changeprice></s_total>\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "El texto es bien detectado, pero vemos que el modelo agrega tokens / tagas al inicio y final del texto detectado, como si se tratara de una tabla / lista de precios."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Probamos evaluar el modelo con el dataset de test "
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T21:01:43.850391Z",
     "start_time": "2025-06-18T21:01:31.025554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "from vpc3_proyecto.model_evaluation.utils import manual_evaluate\n",
    "\n",
    "model.eval()  # Set to evaluation mode\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "metrics = manual_evaluate(\n",
    "    model=model,\n",
    "    dataset=test_dataset,\n",
    "    processor=processor,\n",
    "    max_samples=None  # Start small, then increase if successful\n",
    ")\n",
    "print(metrics)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2348 [00:12<1:09:20,  1.78s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39meval()  \u001B[38;5;66;03m# Set to evaluation mode\u001B[39;00m\n\u001B[1;32m      4\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n\u001B[0;32m----> 6\u001B[0m metrics \u001B[38;5;241m=\u001B[39m manual_evaluate(\n\u001B[1;32m      7\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m      8\u001B[0m     dataset\u001B[38;5;241m=\u001B[39mtest_dataset,\n\u001B[1;32m      9\u001B[0m     processor\u001B[38;5;241m=\u001B[39mprocessor,\n\u001B[1;32m     10\u001B[0m     max_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# Start small, then increase if successful\u001B[39;00m\n\u001B[1;32m     11\u001B[0m )\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(metrics)\n",
      "File \u001B[0;32m~/CEIA/vpc3-proyecto/vpc3_proyecto/model_evaluation/utils.py:71\u001B[0m, in \u001B[0;36mmanual_evaluate\u001B[0;34m(model, dataset, processor, max_samples, save_path)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;66;03m# 2. Generate prediction\u001B[39;00m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 71\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[1;32m     72\u001B[0m         pixel_values,\n\u001B[1;32m     73\u001B[0m         max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m,\n\u001B[1;32m     74\u001B[0m         pad_token_id\u001B[38;5;241m=\u001B[39mprocessor\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mpad_token_id,\n\u001B[1;32m     75\u001B[0m         num_beams\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     76\u001B[0m     )\n\u001B[1;32m     78\u001B[0m \u001B[38;5;66;03m# 3. Decode prediction\u001B[39;00m\n\u001B[1;32m     79\u001B[0m pred_text \u001B[38;5;241m=\u001B[39m processor\u001B[38;5;241m.\u001B[39mbatch_decode(outputs, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/transformers/generation/utils.py:2597\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001B[0m\n\u001B[1;32m   2589\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   2590\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   2591\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences,\n\u001B[1;32m   2592\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   2593\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2594\u001B[0m     )\n\u001B[1;32m   2596\u001B[0m     \u001B[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[0;32m-> 2597\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sample(\n\u001B[1;32m   2598\u001B[0m         input_ids,\n\u001B[1;32m   2599\u001B[0m         logits_processor\u001B[38;5;241m=\u001B[39mprepared_logits_processor,\n\u001B[1;32m   2600\u001B[0m         stopping_criteria\u001B[38;5;241m=\u001B[39mprepared_stopping_criteria,\n\u001B[1;32m   2601\u001B[0m         generation_config\u001B[38;5;241m=\u001B[39mgeneration_config,\n\u001B[1;32m   2602\u001B[0m         synced_gpus\u001B[38;5;241m=\u001B[39msynced_gpus,\n\u001B[1;32m   2603\u001B[0m         streamer\u001B[38;5;241m=\u001B[39mstreamer,\n\u001B[1;32m   2604\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2605\u001B[0m     )\n\u001B[1;32m   2607\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SAMPLE, GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH):\n\u001B[1;32m   2608\u001B[0m     \u001B[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001B[39;00m\n\u001B[1;32m   2609\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   2610\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   2611\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[1;32m   2612\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   2613\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2614\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/transformers/generation/utils.py:3548\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   3545\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3546\u001B[0m     is_prefill \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m-> 3548\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_unfinished_sequences(this_peer_finished, synced_gpus, device\u001B[38;5;241m=\u001B[39minput_ids\u001B[38;5;241m.\u001B[39mdevice):\n\u001B[1;32m   3549\u001B[0m     \u001B[38;5;66;03m# prepare model inputs\u001B[39;00m\n\u001B[1;32m   3550\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation(input_ids, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[1;32m   3552\u001B[0m     \u001B[38;5;66;03m# prepare variable output controls (note: some models won't accept all output controls)\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Entrenamiento (fine tuning)"
  },
  {
   "metadata": {
    "id": "IRTFO3Qx6o-H",
    "ExecuteTime": {
     "end_time": "2025-06-18T21:01:46.890080Z",
     "start_time": "2025-06-18T21:01:46.888248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\" # no utilizamos weights and biases"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T21:01:49.487527Z",
     "start_time": "2025-06-18T21:01:49.459981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=os.path.join(os.getenv(\"CHECKPOINT_DIR\"),\"donut-finetuned-coco2014\"),\n",
    "    per_device_train_batch_size=1,  # Minimum possible\n",
    "    gradient_accumulation_steps=1,  # No accumulation\n",
    "    fp16=True,                      # Mixed precision\n",
    "    gradient_checkpointing=True,    # Memory optimization\n",
    "    optim=\"adamw_8bit\",             # 8-bit optimizer\n",
    "    eval_strategy=\"no\",\n",
    "    per_device_eval_batch_size=1,\n",
    "    save_strategy=\"epoch\",             # Disable checkpoints\n",
    "    logging_steps=50,\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=1              # Start with 1 epoch\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "id": "habLhitB4im7",
    "ExecuteTime": {
     "end_time": "2025-06-18T21:02:02.778350Z",
     "start_time": "2025-06-18T21:02:01.904647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from vpc3_proyecto.model_evaluation.utils import compute_metrics\n",
    "from functools import partial\n",
    "from transformers import Seq2SeqTrainer \n",
    "compute_metrics_bound = partial(compute_metrics, donut_processor=processor)\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics_bound,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T21:02:40.832814Z",
     "start_time": "2025-06-18T21:02:09.123348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache() # limpiamos cache\n",
    "\n",
    "trainer.train()\n",
    "# trainer.train(resume_from_checkpoint=True)  # Automatically finds latest checkpoint"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing`. Setting `use_cache=False`...\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='16440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   63/16440 00:28 < 2:08:28, 2.12 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.554900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache() \u001B[38;5;66;03m# limpiamos cache\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/transformers/trainer.py:2240\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   2238\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   2239\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[1;32m   2241\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[1;32m   2242\u001B[0m         resume_from_checkpoint\u001B[38;5;241m=\u001B[39mresume_from_checkpoint,\n\u001B[1;32m   2243\u001B[0m         trial\u001B[38;5;241m=\u001B[39mtrial,\n\u001B[1;32m   2244\u001B[0m         ignore_keys_for_eval\u001B[38;5;241m=\u001B[39mignore_keys_for_eval,\n\u001B[1;32m   2245\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/transformers/trainer.py:2560\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2554\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[1;32m   2555\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(model, inputs, num_items_in_batch)\n\u001B[1;32m   2557\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   2558\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   2559\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[0;32m-> 2560\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   2561\u001B[0m ):\n\u001B[1;32m   2562\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   2563\u001B[0m     tr_loss \u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m+\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n\u001B[1;32m   2564\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T21:02:47.462182Z",
     "start_time": "2025-06-18T21:02:45.942984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from vpc3_proyecto.model_evaluation.utils import get_last_checkpoint_folder\n",
    "\n",
    "last_ckpt = get_last_checkpoint_folder(training_args.output_dir)\n",
    "\n",
    "manually_saved_folder = os.path.join(last_ckpt, \"manually-saved\")\n",
    "\n",
    "if last_ckpt:\n",
    "    print(f\"✅ Último checkpoint: {last_ckpt}\")\n",
    "    processor.save_pretrained(manually_saved_folder)\n",
    "    trainer.save_model(manually_saved_folder)\n",
    "    print(\"✅ Processor guardado en el directorio manual save dentro del checkpoint: \"+manually_saved_folder)\n",
    "else:\n",
    "    print(\"❌ No se encontraron checkpoints\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Último checkpoint: ./donut-finetuned-coco2014/checkpoint-15656\n",
      "✅ Processor guardado en el directorio manual save dentro del checkpoint: ./donut-finetuned-coco2014/checkpoint-15656/manually-saved\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCLXJEtE9zro"
   },
   "source": "# Evaluamos modelo finetuneado  para ver si mejoro alguna metrica"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T21:03:57.502201Z",
     "start_time": "2025-06-18T21:03:55.914965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import glob\n",
    "from transformers import VisionEncoderDecoderModel, DonutProcessor\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "last_ckpt = get_last_checkpoint_folder(training_args.output_dir)\n",
    "manually_saved_folder = os.path.join(last_ckpt, \"manually-saved\")\n",
    "\n",
    "\n",
    "processor = DonutProcessor.from_pretrained(manually_saved_folder)\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\n",
    "    manually_saved_folder,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16  \n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = DonutTextDatasetFromCocoTextV2Raw(\n",
    "    img_dir_test,  \n",
    "    ann_coco_text,\n",
    "    processor=processor,\n",
    "    max_length=512\n",
    ")\n",
    "model.config.decoder_start_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T21:03:16.690063Z",
     "start_time": "2025-06-18T21:03:16.687137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Model device: {model.device}\")\n",
    "print(f\"Vocab size: {model.config}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n",
      "Vocab size: VisionEncoderDecoderConfig {\n",
      "  \"architectures\": [\n",
      "    \"VisionEncoderDecoderModel\"\n",
      "  ],\n",
      "  \"decoder\": {\n",
      "    \"activation_dropout\": 0.0,\n",
      "    \"activation_function\": \"gelu\",\n",
      "    \"add_cross_attention\": true,\n",
      "    \"add_final_layer_norm\": true,\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"classifier_dropout\": 0.0,\n",
      "    \"d_model\": 1024,\n",
      "    \"decoder_attention_heads\": 16,\n",
      "    \"decoder_ffn_dim\": 4096,\n",
      "    \"decoder_layerdrop\": 0.0,\n",
      "    \"decoder_layers\": 4,\n",
      "    \"dropout\": 0.1,\n",
      "    \"encoder_attention_heads\": 16,\n",
      "    \"encoder_ffn_dim\": 4096,\n",
      "    \"encoder_layerdrop\": 0.0,\n",
      "    \"encoder_layers\": 12,\n",
      "    \"init_std\": 0.02,\n",
      "    \"is_decoder\": true,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"max_position_embeddings\": 768,\n",
      "    \"model_type\": \"mbart\",\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"scale_embedding\": true,\n",
      "    \"torch_dtype\": \"float16\",\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 57580\n",
      "  },\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"encoder\": {\n",
      "    \"attention_probs_dropout_prob\": 0.0,\n",
      "    \"depths\": [\n",
      "      2,\n",
      "      2,\n",
      "      14,\n",
      "      2\n",
      "    ],\n",
      "    \"drop_path_rate\": 0.1,\n",
      "    \"embed_dim\": 128,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.0,\n",
      "    \"hidden_size\": 1024,\n",
      "    \"image_size\": [\n",
      "      1280,\n",
      "      960\n",
      "    ],\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"layer_norm_eps\": 1e-05,\n",
      "    \"mlp_ratio\": 4.0,\n",
      "    \"model_type\": \"donut-swin\",\n",
      "    \"num_channels\": 3,\n",
      "    \"num_heads\": [\n",
      "      4,\n",
      "      8,\n",
      "      16,\n",
      "      32\n",
      "    ],\n",
      "    \"num_layers\": 4,\n",
      "    \"patch_size\": 4,\n",
      "    \"path_norm\": true,\n",
      "    \"qkv_bias\": true,\n",
      "    \"torch_dtype\": \"float16\",\n",
      "    \"use_absolute_embeddings\": false,\n",
      "    \"window_size\": 10\n",
      "  },\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"model_type\": \"vision-encoder-decoder\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.52.4\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X6dQKURI7O04",
    "ExecuteTime": {
     "end_time": "2025-06-18T21:04:03.726904Z",
     "start_time": "2025-06-18T21:03:59.938003Z"
    }
   },
   "source": [
    "metrics = manual_evaluate(\n",
    "    model=model,\n",
    "    dataset=test_dataset,\n",
    "    processor=processor,\n",
    "    max_samples=None  ,\n",
    "    results_save_path=manually_saved_folder\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2348 [00:03<09:18,  4.18it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m metrics \u001B[38;5;241m=\u001B[39m manual_evaluate(\n\u001B[1;32m      2\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m      3\u001B[0m     dataset\u001B[38;5;241m=\u001B[39mtest_dataset,\n\u001B[1;32m      4\u001B[0m     processor\u001B[38;5;241m=\u001B[39mprocessor,\n\u001B[1;32m      5\u001B[0m     max_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m  ,\n\u001B[1;32m      6\u001B[0m     save_path\u001B[38;5;241m=\u001B[39mmanually_saved_folder\n\u001B[1;32m      7\u001B[0m )\n",
      "File \u001B[0;32m~/CEIA/vpc3-proyecto/vpc3_proyecto/model_evaluation/utils.py:71\u001B[0m, in \u001B[0;36mmanual_evaluate\u001B[0;34m(model, dataset, processor, max_samples, save_path)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;66;03m# 2. Generate prediction\u001B[39;00m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 71\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[1;32m     72\u001B[0m         pixel_values,\n\u001B[1;32m     73\u001B[0m         max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m,\n\u001B[1;32m     74\u001B[0m         pad_token_id\u001B[38;5;241m=\u001B[39mprocessor\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mpad_token_id,\n\u001B[1;32m     75\u001B[0m         num_beams\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     76\u001B[0m     )\n\u001B[1;32m     78\u001B[0m \u001B[38;5;66;03m# 3. Decode prediction\u001B[39;00m\n\u001B[1;32m     79\u001B[0m pred_text \u001B[38;5;241m=\u001B[39m processor\u001B[38;5;241m.\u001B[39mbatch_decode(outputs, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/transformers/generation/utils.py:2597\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001B[0m\n\u001B[1;32m   2589\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   2590\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   2591\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences,\n\u001B[1;32m   2592\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   2593\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2594\u001B[0m     )\n\u001B[1;32m   2596\u001B[0m     \u001B[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[0;32m-> 2597\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sample(\n\u001B[1;32m   2598\u001B[0m         input_ids,\n\u001B[1;32m   2599\u001B[0m         logits_processor\u001B[38;5;241m=\u001B[39mprepared_logits_processor,\n\u001B[1;32m   2600\u001B[0m         stopping_criteria\u001B[38;5;241m=\u001B[39mprepared_stopping_criteria,\n\u001B[1;32m   2601\u001B[0m         generation_config\u001B[38;5;241m=\u001B[39mgeneration_config,\n\u001B[1;32m   2602\u001B[0m         synced_gpus\u001B[38;5;241m=\u001B[39msynced_gpus,\n\u001B[1;32m   2603\u001B[0m         streamer\u001B[38;5;241m=\u001B[39mstreamer,\n\u001B[1;32m   2604\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2605\u001B[0m     )\n\u001B[1;32m   2607\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SAMPLE, GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH):\n\u001B[1;32m   2608\u001B[0m     \u001B[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001B[39;00m\n\u001B[1;32m   2609\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   2610\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   2611\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[1;32m   2612\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   2613\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2614\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/transformers/generation/utils.py:3560\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   3558\u001B[0m     is_prefill \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   3559\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3560\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model_forward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_inputs, return_dict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   3562\u001B[0m \u001B[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001B[39;00m\n\u001B[1;32m   3563\u001B[0m model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_model_kwargs_for_generation(\n\u001B[1;32m   3564\u001B[0m     outputs,\n\u001B[1;32m   3565\u001B[0m     model_kwargs,\n\u001B[1;32m   3566\u001B[0m     is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   3567\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_vision_encoder_decoder.py:553\u001B[0m, in \u001B[0;36mVisionEncoderDecoderModel.forward\u001B[0;34m(self, pixel_values, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m     decoder_input_ids \u001B[38;5;241m=\u001B[39m shift_tokens_right(\n\u001B[1;32m    549\u001B[0m         labels, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpad_token_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mdecoder_start_token_id\n\u001B[1;32m    550\u001B[0m     )\n\u001B[1;32m    552\u001B[0m \u001B[38;5;66;03m# Decode\u001B[39;00m\n\u001B[0;32m--> 553\u001B[0m decoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(\n\u001B[1;32m    554\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39mdecoder_input_ids,\n\u001B[1;32m    555\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mdecoder_attention_mask,\n\u001B[1;32m    556\u001B[0m     encoder_hidden_states\u001B[38;5;241m=\u001B[39mencoder_hidden_states,\n\u001B[1;32m    557\u001B[0m     encoder_attention_mask\u001B[38;5;241m=\u001B[39mencoder_attention_mask,\n\u001B[1;32m    558\u001B[0m     inputs_embeds\u001B[38;5;241m=\u001B[39mdecoder_inputs_embeds,\n\u001B[1;32m    559\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m    560\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[1;32m    561\u001B[0m     use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[1;32m    562\u001B[0m     past_key_values\u001B[38;5;241m=\u001B[39mpast_key_values,\n\u001B[1;32m    563\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m    564\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs_decoder,\n\u001B[1;32m    565\u001B[0m )\n\u001B[1;32m    567\u001B[0m \u001B[38;5;66;03m# Compute loss independent from decoder (as some shift the logits inside them)\u001B[39;00m\n\u001B[1;32m    568\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:2118\u001B[0m, in \u001B[0;36mMBartForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[1;32m   2115\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m   2117\u001B[0m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[0;32m-> 2118\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mdecoder(\n\u001B[1;32m   2119\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   2120\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m   2121\u001B[0m     encoder_hidden_states\u001B[38;5;241m=\u001B[39mencoder_hidden_states,\n\u001B[1;32m   2122\u001B[0m     encoder_attention_mask\u001B[38;5;241m=\u001B[39mencoder_attention_mask,\n\u001B[1;32m   2123\u001B[0m     head_mask\u001B[38;5;241m=\u001B[39mhead_mask,\n\u001B[1;32m   2124\u001B[0m     cross_attn_head_mask\u001B[38;5;241m=\u001B[39mcross_attn_head_mask,\n\u001B[1;32m   2125\u001B[0m     past_key_values\u001B[38;5;241m=\u001B[39mpast_key_values,\n\u001B[1;32m   2126\u001B[0m     inputs_embeds\u001B[38;5;241m=\u001B[39minputs_embeds,\n\u001B[1;32m   2127\u001B[0m     use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[1;32m   2128\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m   2129\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[1;32m   2130\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m   2131\u001B[0m     cache_position\u001B[38;5;241m=\u001B[39mcache_position,\n\u001B[1;32m   2132\u001B[0m )\n\u001B[1;32m   2134\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlm_head(outputs[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m   2136\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:1332\u001B[0m, in \u001B[0;36mMBartDecoder.forward\u001B[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[1;32m   1318\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m   1319\u001B[0m         decoder_layer\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m   1320\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1329\u001B[0m         cache_position,\n\u001B[1;32m   1330\u001B[0m     )\n\u001B[1;32m   1331\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1332\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m decoder_layer(\n\u001B[1;32m   1333\u001B[0m         hidden_states,\n\u001B[1;32m   1334\u001B[0m         attention_mask\u001B[38;5;241m=\u001B[39mcausal_mask,\n\u001B[1;32m   1335\u001B[0m         encoder_hidden_states\u001B[38;5;241m=\u001B[39mencoder_hidden_states,\n\u001B[1;32m   1336\u001B[0m         encoder_attention_mask\u001B[38;5;241m=\u001B[39mencoder_attention_mask,\n\u001B[1;32m   1337\u001B[0m         layer_head_mask\u001B[38;5;241m=\u001B[39m(head_mask[idx] \u001B[38;5;28;01mif\u001B[39;00m head_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1338\u001B[0m         cross_attn_layer_head_mask\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1339\u001B[0m             cross_attn_head_mask[idx] \u001B[38;5;28;01mif\u001B[39;00m cross_attn_head_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1340\u001B[0m         ),\n\u001B[1;32m   1341\u001B[0m         past_key_value\u001B[38;5;241m=\u001B[39mpast_key_values,\n\u001B[1;32m   1342\u001B[0m         output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m   1343\u001B[0m         use_cache\u001B[38;5;241m=\u001B[39muse_cache,\n\u001B[1;32m   1344\u001B[0m         cache_position\u001B[38;5;241m=\u001B[39mcache_position,\n\u001B[1;32m   1345\u001B[0m     )\n\u001B[1;32m   1346\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1348\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:656\u001B[0m, in \u001B[0;36mMBartDecoderLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache, cache_position)\u001B[0m\n\u001B[1;32m    653\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mself_attn_layer_norm(hidden_states)\n\u001B[1;32m    655\u001B[0m \u001B[38;5;66;03m# Self Attention\u001B[39;00m\n\u001B[0;32m--> 656\u001B[0m hidden_states, self_attn_weights, past_key_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mself_attn(\n\u001B[1;32m    657\u001B[0m     hidden_states\u001B[38;5;241m=\u001B[39mhidden_states,\n\u001B[1;32m    658\u001B[0m     past_key_value\u001B[38;5;241m=\u001B[39mpast_key_value,\n\u001B[1;32m    659\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m    660\u001B[0m     layer_head_mask\u001B[38;5;241m=\u001B[39mlayer_head_mask,\n\u001B[1;32m    661\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m    662\u001B[0m     cache_position\u001B[38;5;241m=\u001B[39mcache_position,\n\u001B[1;32m    663\u001B[0m )\n\u001B[1;32m    664\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mdropout(hidden_states, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n\u001B[1;32m    665\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:459\u001B[0m, in \u001B[0;36mMBartSdpaAttention.forward\u001B[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions, cache_position)\u001B[0m\n\u001B[1;32m    457\u001B[0m     value_states \u001B[38;5;241m=\u001B[39m curr_past_key_value\u001B[38;5;241m.\u001B[39mvalue_cache[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_idx]\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 459\u001B[0m     key_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk_proj(current_states)\n\u001B[1;32m    460\u001B[0m     value_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv_proj(current_states)\n\u001B[1;32m    461\u001B[0m     key_states \u001B[38;5;241m=\u001B[39m key_states\u001B[38;5;241m.\u001B[39mview(bsz, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/anaconda3/envs/CEIA/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "052e6329b0534130812ba5ca45b083db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0abea91c811a4c3da3315f51db11d0cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ed6d36be6fa4797bf9b9b8c095b6475": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3eeacb8cc59b407fb16b54fe1c883f5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fdbcc1df4bb4b3b8925a824e8088f09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "437a1a92761e44bdb68e076ac3b3da9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a23a14bae46486dbe3bdc4a9cab1409": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "524ba3a721264edc9d081615489cd95d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_437a1a92761e44bdb68e076ac3b3da9b",
      "placeholder": "​",
      "style": "IPY_MODEL_0abea91c811a4c3da3315f51db11d0cd",
      "value": "Map (num_proc=2): 100%"
     }
    },
    "5cd3b7ea4c774594bd10ad7e74d84d2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_524ba3a721264edc9d081615489cd95d",
       "IPY_MODEL_a03fc8049134429c8bfdad054fa4b9c7",
       "IPY_MODEL_f1430cbbd2ec4b7ba98e703a9e28b343"
      ],
      "layout": "IPY_MODEL_3eeacb8cc59b407fb16b54fe1c883f5a"
     }
    },
    "5ef7259729eb4a59bb392a920ecebc3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "636925ca49db4f9db22f0adf2271fb4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af807c2961134a6b84e103efecc1c338",
      "placeholder": "​",
      "style": "IPY_MODEL_85968d8cbd1a49ecbbe3a66b7a2506f9",
      "value": " 1000/1000 [00:29&lt;00:00, 250.78 examples/s]"
     }
    },
    "63c0fe8307d04343b09deb9028d92d6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ac115587cbed4d95ba341da7974e3969",
       "IPY_MODEL_e1fd27c905a84959bac499d1b80f78d8",
       "IPY_MODEL_636925ca49db4f9db22f0adf2271fb4d"
      ],
      "layout": "IPY_MODEL_2ed6d36be6fa4797bf9b9b8c095b6475"
     }
    },
    "73652eb375bb40d59a4c30969dc9f550": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "741bac5ce3494d2fbfe6d4b241b1bb8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80153adaf2564a9081ab626832a77969": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85968d8cbd1a49ecbbe3a66b7a2506f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a03fc8049134429c8bfdad054fa4b9c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73652eb375bb40d59a4c30969dc9f550",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ef7259729eb4a59bb392a920ecebc3b",
      "value": 2000
     }
    },
    "ac115587cbed4d95ba341da7974e3969": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_052e6329b0534130812ba5ca45b083db",
      "placeholder": "​",
      "style": "IPY_MODEL_4a23a14bae46486dbe3bdc4a9cab1409",
      "value": "Map (num_proc=2): 100%"
     }
    },
    "af807c2961134a6b84e103efecc1c338": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7d7acd6a9034b94ae5b6c18fd532020": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1fd27c905a84959bac499d1b80f78d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7d7acd6a9034b94ae5b6c18fd532020",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3fdbcc1df4bb4b3b8925a824e8088f09",
      "value": 1000
     }
    },
    "f1430cbbd2ec4b7ba98e703a9e28b343": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_741bac5ce3494d2fbfe6d4b241b1bb8c",
      "placeholder": "​",
      "style": "IPY_MODEL_80153adaf2564a9081ab626832a77969",
      "value": " 2000/2000 [00:35&lt;00:00,  4.71 examples/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
